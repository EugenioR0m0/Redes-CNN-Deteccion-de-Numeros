{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56f8d60-13ac-4b93-9a72-fc602508aa9c",
   "metadata": {},
   "source": [
    "Este programa carga tu modelo VGG final y realiza clasificaci√≥n de d√≠gitos en tiempo real usando la c√°mara. Cada cuadro capturado se preprocesa exactamente igual que tus im√°genes del dataset (recorte, escala de grises, resize, binarizaci√≥n OTSU e inversi√≥n). Despu√©s, el modelo predice el d√≠gito y su probabilidad. La ventana principal muestra la c√°mara con el ROI marcado y las probabilidades de cada clase; adem√°s, muestra a un lado la versi√≥n preprocesada que realmente entra al modelo. El sistema actualiza las predicciones continuamente hasta que el usuario presiona q para salir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc006c16-4e76-4990-8349-f4ffe3c5ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "IMG_SIZE = 280\n",
    "MODEL_PATH = \"vgg_final_model_2.keras\"\n",
    "\n",
    "model = load_model(MODEL_PATH)\n",
    "print(\"Modelo cargado ‚úî\")\n",
    "\n",
    "def preprocess_realtime(frame):\n",
    "    \"\"\"\n",
    "    Preprocesa un frame EXACTAMENTE igual que el dataset:\n",
    "    1. Recorte central (ROI)\n",
    "    2. Gris\n",
    "    3. Redimensionar a 280x280\n",
    "    4. Binarizaci√≥n OTSU\n",
    "    5. Invertir\n",
    "    6. Expandir dims para que entre al modelo\n",
    "    \"\"\"\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # ---- 1. DEFINIR ROI CENTRAL ----\n",
    "    side = min(h, w)\n",
    "    cx, cy = w // 2, h // 2\n",
    "\n",
    "    x1 = cx - side // 4\n",
    "    x2 = cx + side // 4\n",
    "    y1 = cy - side // 4\n",
    "    y2 = cy + side // 4\n",
    "\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # ---- 2. GRAYSCALE ----\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ---- 3. RESIZE ----\n",
    "    resized = cv2.resize(gray, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # ---- 4. BINARIZACI√ìN OTSU ----\n",
    "    _, thresh = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # ---- 5. INVERTIR ----\n",
    "    inverted = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # ---- 6. NORMALIZAR + EXPANDIR ----\n",
    "    norm = inverted.astype(\"float32\") / 255.0\n",
    "    model_input = norm.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    # regresamos tambi√©n la imagen preprocesada para visualizar\n",
    "    return model_input, inverted, (x1, y1, x2, y2)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"No se pudo abrir c√°mara.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Coloca el d√≠gito dentro del cuadro amarillo. Presiona 'q' para salir.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # --- PREPROCESAMIENTO ---\n",
    "    model_input, processed_img, (x1, y1, x2, y2) = preprocess_realtime(frame)\n",
    "\n",
    "    # --- PREDICCI√ìN ---\n",
    "    preds = model.predict(model_input, verbose=0)[0]\n",
    "    class_id = np.argmax(preds)\n",
    "    confidence = preds[class_id]\n",
    "\n",
    "    # --- DIBUJAR ROI ---\n",
    "    display = frame.copy()\n",
    "    cv2.rectangle(display, (x1, y1), (x2, y2), (0,255,255), 2)\n",
    "\n",
    "    # --- MOSTRAR PROBABILIDADES ---\n",
    "    for i, p in enumerate(preds):\n",
    "        color = (0,255,0) if i == class_id else (0,0,255)\n",
    "        cv2.putText(display, f\"{i}: {p:.3f}\", (10, 30 + i*25),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # --- MOSTRAR IMAGEN PROCESADA ---\n",
    "    preview = cv2.cvtColor(processed_img, cv2.COLOR_GRAY2BGR)\n",
    "    preview = cv2.resize(preview, (200, display.shape[0]))\n",
    "    combined = np.hstack([display, preview])\n",
    "\n",
    "    cv2.putText(combined, f\"Pred: {class_id} ({confidence:.2f})\",\n",
    "                (10, combined.shape[0]-15),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Clasificaci√≥n tiempo real\", combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ec522-dbdd-4d3f-8390-5dc5a79a9bfa",
   "metadata": {},
   "source": [
    "Este programa implementa un sistema de OCR de m√∫ltiples d√≠gitos en tiempo real usando tu modelo VGG final. La c√°mara captura cada cuadro y se procesa siguiendo exactamente el pipeline del profesor: conversi√≥n a escala de grises, desenfoque para reducir ruido, binarizaci√≥n din√°mica con OTSU, inversi√≥n y dilataci√≥n para unir trazos. Luego se detectan contornos en la imagen dilatada y, para cada contorno v√°lido, se extrae el recorte correspondiente y se preprocesa con el mismo flujo usado en tu dataset (resize, OTSU, invertir, normalizar). El modelo clasifica cada d√≠gito encontrado y la predicci√≥n se dibuja sobre un bounding box en la imagen original. Se muestran dos ventanas: la imagen original con detecciones y la versi√≥n binarizada/dilatada usada para localizar los d√≠gitos. El sistema corre de manera continua hasta que el usuario presiona Q para salir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8264c9dc-fe12-460c-ae98-42ad5e9a1553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo...\n",
      "‚úî Modelo cargado correctamente.\n",
      "\n",
      "üé• OCR multi-d√≠gitos en tiempo real\n",
      "Presiona Q para salir.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_PATH = \"vgg_final_model_2.keras\"\n",
    "IMG_SIZE = 280\n",
    "\n",
    "print(\"Cargando modelo...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "print(\"‚úî Modelo cargado correctamente.\\n\")\n",
    "\n",
    "def preprocess_for_model(roi_gray):\n",
    "    \"\"\"\n",
    "    roi_gray: recorte en escala de grises del d√≠gito\n",
    "    \"\"\"\n",
    "    # 1) Resize a 280x280\n",
    "    resized = cv2.resize(roi_gray, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 2) Binarizaci√≥n OTSU\n",
    "    _, thresh = cv2.threshold(resized, 0, 255,\n",
    "                              cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 3) Invertir (d√≠gito blanco, fondo negro)\n",
    "    inverted = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # 4) Normalizar + reshape\n",
    "    norm = inverted.astype(\"float32\") / 255.0\n",
    "    model_input = norm.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "    return model_input\n",
    "\n",
    "\n",
    "# ============================\n",
    "# OCR EN TIEMPO REAL (PIPELINE DEL PROFE)\n",
    "# ============================\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå No se pudo abrir la c√°mara\")\n",
    "    raise SystemExit\n",
    "\n",
    "print(\"üé• OCR multi-d√≠gitos en tiempo real\")\n",
    "print(\"Presiona Q para salir.\\n\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Frame no le√≠do.\")\n",
    "        break\n",
    "\n",
    "    # Copia para dibujar\n",
    "    display = frame.copy()\n",
    "\n",
    "    # ------------------------------\n",
    "    # 1. Lee la imagen  -> ya la tenemos (frame)\n",
    "    # 2. Convierte a escala de grises\n",
    "    # ------------------------------\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3. Aplica blur para reducir ruido\n",
    "    #    (kernel se puede ajustar experimentalmente)\n",
    "    # ------------------------------\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4. Binariza (umbral din√°mico OTSU) + invertimos\n",
    "    #    para que el d√≠gito sea blanco\n",
    "    # ------------------------------\n",
    "    _, binary = cv2.threshold(\n",
    "        blur, 0, 255,\n",
    "        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # 5. Dilataci√≥n para unir trazos\n",
    "    #    (kernel e iteraciones ajustables)\n",
    "    # ------------------------------\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.dilate(binary, kernel, iterations=2)\n",
    "\n",
    "    # ------------------------------\n",
    "    # 6. Buscar contornos en la imagen dilatada\n",
    "    # ------------------------------\n",
    "    contours, _ = cv2.findContours(\n",
    "        dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # Opcional: ordenar contornos de izquierda a derecha\n",
    "    contours = sorted(contours, key=lambda c: cv2.boundingRect(c)[0])\n",
    "\n",
    "    detected_digits = []\n",
    "\n",
    "    # ------------------------------\n",
    "    # 7. Iterar por cada contorno\n",
    "    # ------------------------------\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "        # Ignorar ruido muy peque√±o\n",
    "        if w < 20 or h < 20:\n",
    "            continue\n",
    "\n",
    "        # Genera bounding box\n",
    "        cv2.rectangle(display, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Extrae pedazo de imagen de la IMAGEN ORIGINAL EN GRIS\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "\n",
    "        # Preprocesar ROI para el modelo (tu pipeline)\n",
    "        model_input = preprocess_for_model(roi_gray)\n",
    "\n",
    "        # Predicci√≥n con el modelo\n",
    "        preds = model.predict(model_input, verbose=0)[0]\n",
    "        digit = np.argmax(preds)\n",
    "        conf = preds[digit]\n",
    "\n",
    "        detected_digits.append((digit, conf, x, y, w, h))\n",
    "\n",
    "        # Dibujar etiqueta sobre el bounding box\n",
    "        cv2.putText(\n",
    "            display,\n",
    "            f\"{digit} ({conf:.2f})\",\n",
    "            (x, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    # ------------------------------\n",
    "    # 8. Visualizaci√≥n\n",
    "    #    - display: imagen original + bounding boxes + etiquetas\n",
    "    #    - dilated: \"filtro\" blur + binarizaci√≥n + dilataci√≥n\n",
    "    # ------------------------------\n",
    "    cv2.imshow(\"OCR - Original con detecciones\", display)\n",
    "    cv2.imshow(\"OCR - Blur + Binarizacion + Dilatacion\", dilated)\n",
    "\n",
    "    # Salida con 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
